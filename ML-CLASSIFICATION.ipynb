{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Ay2loQjFtpJ_"},"outputs":[],"source":["# Choose what to run\n","\n","Colab = True    # set to True if running this notebook in Colab\n","BigRam = True   # set to True if you have plenty of RAM and want to keep all models in memory\n","                # WARNING: some of these models are very big\n","\n","BoW = False     # set to True if you want to run Bag of Words\n","BoWFT = False    # set to True if you want to Fine-Tune the Bag of Words\n","\n","CNN = True      # set to True if you want to run Convolutional Neural Network\n","CNNFT = False    # set to True if you want to Fine-Tune the Convolutional Neural Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fZzIe_Bvl0PP"},"outputs":[],"source":["# specify the local directory to saved models and image data are found\n","\n","if not Colab:\n","    LocalDir = 'C:/Users/Filippo/Documents/Docs/Uni/AI/First Year/Second Semester/Supervised Learning/Exam/'"]},{"cell_type":"markdown","metadata":{"id":"tXBcphwRAgkM"},"source":["# üò° Python stuff"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4JdAIdiDs9oC"},"outputs":[],"source":["# Colab imports\n","if Colab:\n","    !pip install -q optuna\n","    from google.colab import drive, files\n","\n","import numpy as np                  # numpy because numpy is life\n","from PIL import Image               # Image to read images\n","import os                           # os to handle directories and files\n","import matplotlib.pyplot as plt     # matplotlib for cool graphs\n","import matplotlib.patheffects as pe\n","import pandas as pd                 # pandas for dataset management\n","import cv2                          # cv2 for image transformations\n","from tqdm import tqdm               # tqdm for cool progress bars\n","import random                       # random to generate random values\n","import pickle                       # pickle for saving various data objects\n","import time                         # time to keep track of computational times\n","\n","# torch for neural network stuff\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data as data\n","import torchvision\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from torchsummary import summary\n","\n","# sklearn for clustering stuff\n","from sklearn.feature_extraction import image as skimage\n","from sklearn.cluster import KMeans, MiniBatchKMeans\n","from sklearn.svm import SVC\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.linear_model import SGDClassifier\n","from sklearn import tree\n","from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, VotingClassifier\n","from scipy.special import softmax\n","\n","# optuna for hyperparameter tuning\n","import optuna"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ah83zNVXGmVt"},"outputs":[],"source":["# Check whether GPU is available\n","\n","train_on_gpu = torch.cuda.is_available()\n","if not train_on_gpu:\n","    print('CUDA:\\tNOT available\\nGPU:\\tdeactivated\\n\\t(‚åê‚ñ†_‚ñ†)\\n\\t( ‚Ä¢_‚Ä¢)>‚åê‚ñ†-‚ñ†\\n\\t(‚Ä¢_‚Ä¢)')\n","else:\n","    print('CUDA:\\tavailable\\nGPU:\\tactivated\\n\\t(‚Ä¢_‚Ä¢)\\n\\t( ‚Ä¢_‚Ä¢)>‚åê‚ñ†-‚ñ†\\n\\t(‚åê‚ñ†_‚ñ†)')\n","device = torch.device('cuda:0' if train_on_gpu else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lylzuq-OjoK1"},"outputs":[],"source":["# google Colab stuff\n","\n","if Colab:\n","    # mount drive\n","    drive.mount('/content/gdrive')\n","\n","    # set you Google Drive path\n","    gpath = '/content/gdrive/MyDrive/AI4S&T/Supervised Learning/SUP - Exam/'\n","\n","    # download TinyImageNet.zip\n","    !gdown '1BoE0v0e9gdWFXDLl4Y7en7J4qtt9vC-h'\n","    # unzip dataset\n","    !unzip -n -q '/content/TinyImageNet.zip'\n","    # set Directory\n","    LocalDir = '/content/'\n","\n","    # create useful folders\n","    !mkdir saved\n","    !mkdir saved/classifiers\n","    !mkdir saved/neuralnets\n","    !mkdir saved/studies\n","else:\n","    # create useful folders\n","    if not os.path.isdir(f'{LocalDir}saved'):\n","        os.makedirs(f'{LocalDir}saved')\n","        os.makedirs(f'{LocalDir}saved/classifiers')\n","        os.makedirs(f'{LocalDir}saved/neuralnets')\n","        os.makedirs(f'{LocalDir}saved/studies')"]},{"cell_type":"markdown","metadata":{"id":"EvAa4VP2BFKT"},"source":["# üóÉÔ∏è Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z1dDLf9diH25"},"outputs":[],"source":["# function to display images in a grid\n","\n","def show_images(images, labels = True):\n","    if labels:\n","        imgs = [x[0] for x in images]\n","        labels = [x[1] for x in images]\n","    else:\n","        imgs = images\n","\n","    n_imgs = len(imgs)\n","    r = max(int(np.sqrt(n_imgs)), 2)\n","    c = max(int(np.ceil(n_imgs/r)), 2)\n","\n","    fig, axs = plt.subplots(ncols = c, nrows = r, figsize = (10, 10), gridspec_kw = {'wspace':0, 'hspace':0})\n","    i = 0\n","    for row in range(r):\n","        for col in range(c):\n","            if i < n_imgs:\n","                axs[row, col].imshow(imgs[i])\n","                if labels:\n","                    axs[row, col].set_title(str(labels[i]), loc = 'center', y = 0.05, fontsize = 15, color = 'white',\n","                        path_effects = [pe.withStroke(linewidth = 3, foreground = \"black\")])\n","                axs[row, col].axis('off')\n","            else:\n","                fig.delaxes(axs[row][col])\n","            i += 1\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"00QlBUTgiJbZ"},"outputs":[],"source":["#########################################################################################\n","# Custom Dataset\n","#########################################################################################\n","\n","class DataSet(Dataset):\n","    def __init__(self, data_dir, dataframe, transforms = None):\n","        self.data_dir = data_dir            # data directory where all images are stored\n","        self.transforms = transforms        # transforms to apply to each image\n","\n","        self.data = dataframe.to_numpy()   # save pandas dataframe as numpy array\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        image_name, label = self.data[index]\n","        image_path = os.path.join(self.data_dir, image_name).replace('\\\\','/')\n","\n","        # load image and converts it to RGB (if not already)\n","        image = Image.open(image_path).convert('RGB')\n","\n","        if self.transforms != None:\n","            image = self.transforms(image)\n","\n","        return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KtrFFIENl0Pa"},"outputs":[],"source":["#########################################################################################\n","# Load Data\n","#########################################################################################\n","\n","# Directory containing all images\n","DataDir = LocalDir + 'TinyImageNet/'\n","\n","# Classes to predict\n","NumClasses = 100\n","Classes = np.array([x for x in range(NumClasses)])\n","\n","# DEBUG ONLY: Images to use for faster testing\n","PercentageDataToUse = 1\n","\n","# Augment class 56\n","Augment = False\n","\n","\n","# Split Train data into Train + Validation\n","DF_train_val = pd.read_csv(DataDir + 'train.txt', sep = ' ', header = None, names = ['image_name', 'label'])\n","\n","n_images = DF_train_val.shape[0]\n","train_size = int(0.8 * n_images)\n","val_size = n_images - train_size\n","\n","# Shuffle data around\n","DF_train_val = DF_train_val.sample(frac = 1, random_state = None)\n","\n","# Get data for training and for validation\n","data_train = DF_train_val[ : train_size]\n","data_val = DF_train_val[-val_size : ]\n","\n","# Get data for testing\n","data_test = pd.read_csv(DataDir + 'val.txt', sep = ' ', header = None, names = ['image_name', 'label'])\n","\n","# Print number of Train/Val/Test images\n","print(f'Train:\\t{len(data_train)} images')\n","print(f'Val:\\t{len(data_val)} images')\n","print(f'Test:\\t{len(data_test)} images')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O2dmNCvBl0Pd"},"outputs":[],"source":["# Visualize some Images from the training set\n","n_images = 16\n","random_indices = random.sample(range(len(data_train)), n_images)\n","image_to_display = DataSet(DataDir, data_train.iloc[random_indices])\n","show_images(image_to_display, labels = True)"]},{"cell_type":"markdown","metadata":{"id":"FnvFofOZmsuz"},"source":["## üß¨ Data Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5k6q0cAKmxQL"},"outputs":[],"source":["#########################################################################################\n","# Data Augmentation\n","#########################################################################################\n","\n","# after doing some tests, we found out that class 56\n","# was performing much much worse compared to the others (<0.5 accuracy)\n","# so we can try to augment the images of this class and see what happens\n","\n","\n","# BEFORE:   0.5 ACC\n","if Augment:\n","  # select elements that have label 56\n","  toAug = data_train.loc[data_train['label'] == 56]\n","  NumOld = len(toAug)\n","  print(f'before:\\t{NumOld} images with label 56')\n","\n","  # multiplication factor for number of label 56 images\n","  AugMultiplier = 2\n","  TotalNewImages = int((AugMultiplier+1)*len(toAug))\n","  ToCreate = TotalNewImages - len(toAug)\n","\n","  # check if modified data hasn't already been added to DataFrame\n","  if len(data_train)<80001:\n","      for i in tqdm(range(ToCreate)):\n","          image_name, label = toAug.iloc[i%len(toAug)]\n","\n","          image_path = os.path.join(DataDir, image_name).replace('\\\\','/')\n","\n","          new_row = pd.DataFrame([{'image_name': f'{os.path.splitext(image_name)[0]}_MOD{i//NumOld}.jpg',\n","                                  'label': 56}])\n","\n","          # load image\n","          image = np.array(Image.open(image_path).convert('RGB'))\n","\n","          # flip image randomly\n","          image = cv2.flip(image, random.choice([-1, 0, 1]))\n","\n","          # brigthen or darken image\n","          brightmask = np.ones(image. shape, dtype = 'uint8') * 30\n","          if random.random() > 0.5:\n","              image = cv2.add(image, brightmask)\n","          else:\n","              image = cv2.subtract(image, brightmask)\n","\n","          # rotate image\n","          h, w = image.shape[:2]\n","          rot_mat = cv2.getRotationMatrix2D((w/2,h/2),45,1)\n","          image = cv2.warpAffine(image, rot_mat, (w,h))\n","\n","          # add new image to DataFrame\n","          data_train = pd.concat([data_train, new_row], axis = 0, ignore_index=True)\n","\n","          # save modified image\n","          image = Image.fromarray(image)\n","          image.save(f'{os.path.splitext(image_path)[0]}_MOD{i//NumOld}.jpg')\n","\n","  toAug = data_train.loc[data_train[\"label\"] == 56]\n","  print()\n","  print(f'after:\\t{len(toAug)} images with label 53\\n')\n","\n","  print(f'Train:\\t{len(data_train)} images')\n","  print(f'Val:\\t{len(data_test)} images')\n","  print(f'Test:\\t{len(data_val)} images')\n","  # AFTER:"]},{"cell_type":"markdown","metadata":{"id":"k9Psiv1-ZwAY"},"source":["# üëú Bag of Words"]},{"cell_type":"markdown","metadata":{"id":"5mxL0qYlCSZB"},"source":["## üóÇÔ∏è Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vzHD2JsxiJCB"},"outputs":[],"source":["#########################################################################################\n","# Data Preparation for Bag of Words\n","#########################################################################################\n","\n","# Images will be resized to this value\n","ImageSize = 64"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"911MZHSYl0Pc"},"outputs":[],"source":["# Transform to apply to data\n","transform = transforms.Compose([\n","    transforms.Resize((ImageSize, ImageSize)),\n","])\n","\n","# Datasets initialization\n","data_to_use = int(PercentageDataToUse * len(data_train))\n","TrainDataSet = DataSet(DataDir, data_train[:data_to_use], transform)\n","\n","data_to_use = int(PercentageDataToUse * len(data_test))\n","TestDataSet = DataSet(DataDir, data_test[:data_to_use], transform)\n","\n","# Print Train/Val/Test sizes\n","NumTraining = len(TrainDataSet)\n","print(f'Train:\\t{NumTraining} images')\n","\n","NumTesting = len(TestDataSet)\n","print(f'Test:\\t{NumTesting} images')"]},{"cell_type":"markdown","metadata":{"id":"3BxKTJxAbxYa"},"source":["## üéØ Keypoints Extraction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Jz1n56xjoK6"},"outputs":[],"source":["# SIFT initialization\n","\n","if BoW:\n","    sift = cv2.SIFT_create()\n","    orb = cv2.ORB_create()  # fast but terrible, don't use it :)\n","    Extractor = sift"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OZPobDGLl0Pi"},"outputs":[],"source":["# Extract keypoints and descriptors from each training image\n","\n","if BoW:\n","    # if descriptors are already saved, load them\n","    if os.path.isfile(f'{LocalDir}/saved/descriptors'):\n","        print('Descriptors detected, loading ...')\n","        with open(f'{LocalDir}saved/descriptors', 'rb') as f:\n","            descriptors = pickle.load(f)\n","    else:\n","        # save predictors for each image\n","        descriptors = [[] for _ in range(NumTraining)]\n","        keypoints = [[] for _ in range(NumTraining)]\n","\n","        print(f'Extracting keypoints ...')\n","        for i, img in enumerate(tqdm(TrainDataSet)):\n","            # load image for sift input\n","            img = cv2.cvtColor(np.array(TrainDataSet[i][0]), cv2.COLOR_BGR2GRAY)\n","\n","            # extract keypoints and descriptors\n","            kp, des = Extractor.detectAndCompute(img, mask = None)\n","\n","            # update descriptors lists\n","            if des is not None:\n","                descriptors[i] = des.astype(np.double)\n","                keypoints[i] = kp\n","\n","        # save descriptors to local directory\n","        with open(f'{LocalDir}saved/descriptors', 'wb') as f:\n","            pickle.dump(descriptors, f)\n","\n","    # flatten descriptors (used for training k-means)\n","    descriptors_flat = [descriptor for image_descriptors in descriptors for descriptor in image_descriptors]\n","    print(f'\\nKeypoints:\\t{len(descriptors_flat)} total\\n\\t\\t{len(descriptors_flat)/NumTraining:.2f} average')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KrOyzqAxl0Pj"},"outputs":[],"source":["# # Visualize keypoints from random images\n","\n","if BoW:\n","    n_images = 4\n","    random_indices = random.sample(range(NumTraining), n_images)\n","    img_key = [cv2.drawKeypoints(cv2.cvtColor(np.array(TrainDataSet[i][0]), cv2.COLOR_BGR2GRAY),\n","        keypoints[i], cv2.cvtColor(np.array(TrainDataSet[i][0]), cv2.COLOR_BGR2GRAY)) for i in random_indices]\n","    show_images(img_key, labels = False)"]},{"cell_type":"markdown","metadata":{"id":"eA9JkvMzjoK7"},"source":["## üìä Words Clustering"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XSNOLM3M8FLG"},"outputs":[],"source":["# Preprocess the descriptors applying a Standard scalar\n","\n","if BoW:\n","    from sklearn.preprocessing import StandardScaler\n","    scaler = StandardScaler()\n","\n","    # Apply the scaling to data\n","    descriptors_flat = scaler.fit_transform(np.array(descriptors_flat))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6K0N0MqMl0Pj"},"outputs":[],"source":["# MiniBatchesKmeans initialization\n","\n","if BoW:\n","    # Set dictionary size (== number of words == number of clusters)\n","    NWords = 3000\n","\n","    # Mini Batches k-Means is just k-Means but much much much much much faster\n","    # (and a tidbit, a smidgen less accurate)\n","    MBkMeans = MiniBatchKMeans(n_clusters = NWords, batch_size = 1024, n_init = 'auto', random_state = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kws1JswOjoK8"},"outputs":[],"source":["# Cluster the descriptors using k-means\n","\n","if BoW:\n","    # if model is already saved, load it\n","    if os.path.isfile(f'{LocalDir}saved/classifiers/MBkMeans{NWords}.pkl'):\n","        print('Model detected, loading ...')\n","        with open(f'{LocalDir}saved/classifiers/MBkMeans{NWords}.pkl', 'rb') as f:\n","            MBkMeans = pickle.load(f)\n","\n","    # otherwise train model and save it\n","    else:\n","        MBkMeans.fit(descriptors_flat)\n","        with open(f'{LocalDir}saved/classifiers/MBkMeans{NWords}.pkl', 'wb') as f:\n","            pickle.dump(MBkMeans, f)\n","\n","    # free some RAM\n","    if not BoWFT: del descriptors_flat"]},{"cell_type":"markdown","metadata":{"id":"bTosHjMpjoK8"},"source":["##  üé∞ Classifier\n","Train the classifier on training images with associated labels by feeding it the histogram computed by MBkMeans"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T-uMAkQMjoK8"},"outputs":[],"source":["#########################################################################################\n","# Words clustering\n","#########################################################################################\n","\n","if BoW:\n","    # save histogram and labels for each image\n","    train_histograms = [[] for _ in range(NumTraining)]\n","    train_labels = [-1 for _ in range(NumTraining)]\n","\n","    # compute BoW histogram for each image\n","    print(f'Clustering descriptors ...')\n","    for i in tqdm(range(NumTraining)):\n","        # load descriptors for current image\n","        if not isinstance(descriptors[i], list):\n","          des = scaler.transform(descriptors[i])\n","        else:\n","          des = []\n","\n","        # save label for current image\n","        train_labels[i] = TrainDataSet[i][1]\n","\n","        # compute histogram of words by clustering descriptors\n","        hist = np.zeros(NWords)\n","        if len(des) != 0:\n","            indices = MBkMeans.predict(des)\n","            counts = np.bincount(indices)\n","            hist[:len(counts)] += counts\n","\n","        # normalize histogram and save it\n","        train_histograms[i] = hist/max(1, len(des))\n","\n","    print(f'Done clustering.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ce1xxdpYmpY8"},"outputs":[],"source":["# list of Classifiers\n","Classifiers = [\n","    KNeighborsClassifier(n_neighbors = 10),\n","    SGDClassifier(loss = 'log_loss', penalty = 'l1'),\n","    SVC(kernel = 'poly', degree = 2, cache_size = 512),\n","    tree.DecisionTreeClassifier(),\n","    RandomForestClassifier(n_estimators = 300),\n","    AdaBoostClassifier(n_estimators=500),\n","    BaggingClassifier(),\n","    SVC()\n","    ]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xa62mpFpycNT"},"outputs":[],"source":["#########################################################################################\n","# Classifier Training\n","#########################################################################################\n","\n","if BoW:\n","    # train Classifiers to predict labels of images by their BoW histogram\n","    print(f'\\nTraining classifiers ...')\n","    for _, c in enumerate(Classifiers):\n","        ti = time.time()\n","        print()\n","\n","        # if model is already saved, skip\n","        if os.path.isfile(f'{LocalDir}saved/classifiers/{str(c)[:3]}{NWords}.pkl'):\n","            print(f'{str(c)[:3]} alredy trained ...')\n","\n","        # otherwise train model and save it\n","        else:\n","            print(f'{str(c)[:3]}: training ...')\n","            c.fit(train_histograms, train_labels)\n","            with open(f'{LocalDir}saved/classifiers/{str(c)[:3]}{NWords}.pkl', 'wb') as f:\n","                pickle.dump(c, f)\n","\n","        # delete classifier after saving it to reduce RAM usage\n","        del c\n","\n","        elapsed = time.time() - ti\n","        print(f'\\t... done ({int(elapsed)}s)')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ezMTTGFKjoK9"},"outputs":[],"source":["#########################################################################################\n","# Classifier Testing\n","#########################################################################################\n","if BoW:\n","    # save predicted labels by each classifier\n","    pred_labels_c = [[] for _ in range(len(Classifiers))]\n","\n","    # save histogram and label for each image\n","    test_histograms = [[] for _ in range(NumTesting)]\n","    test_labels = [-1 for _ in range(NumTesting)]\n","\n","    # compute BoW histogram for each image\n","    print(f'Clustering descriptors ...')\n","    for i in tqdm(range(NumTesting)):\n","        # load image for sift input\n","        img = cv2.cvtColor(np.array(TestDataSet[i][0]), cv2.COLOR_BGR2GRAY)\n","\n","        # save label for current image\n","        test_labels[i] = TestDataSet[i][1]\n","\n","        # extract keypoints and descriptors\n","        _, des = Extractor.detectAndCompute(img, mask = None)\n","\n","        # compute histogram of words by clustering descriptors\n","        hist = np.zeros(NWords)\n","        if des is not None:\n","            indices = MBkMeans.predict(scaler.transform(des.astype(np.double)))\n","            counts = np.bincount(indices)\n","            hist[:len(counts)] += counts\n","\n","        test_histograms[i] = hist\n","\n","    # predict labels of images by their BoW histogram\n","    # DYNAMIC: load model from file, use it, and delete it afterwards.\n","    print(f'\\nTesting classifiers ...')\n","    for i, c in enumerate(Classifiers):\n","        ti = time.time()\n","        print(f'\\n{str(c)[:3]}: testing ...')\n","\n","        # load classifier\n","        with open(f'{LocalDir}saved/classifiers/{str(c)[:3]}{NWords}.pkl', 'rb') as f:\n","            c = pickle.load(f)\n","\n","        # predict image label from its BoW histogram\n","        pred_labels_c[i] = c.predict(test_histograms)\n","\n","        # delete model to reduce RAM usage\n","        if not BigRam: del c\n","\n","        elapsed = time.time() - ti\n","        print(f'\\t... done ({int(elapsed)}s)')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XGpyTI6jYsMX"},"outputs":[],"source":["if BoW:\n","    from sklearn.metrics import accuracy_score\n","    print(accuracy_score(test_labels, pred_labels_c[0]))\n","    # se vai giu' nell'evaluation c'e' sta roba"]},{"cell_type":"markdown","metadata":{"id":"Vn28e_3qFwab"},"source":["# üß† Neural Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ino8ewE3L9-L"},"outputs":[],"source":["if Colab and CNN:\n","    !gdown '1er2hFe6mhaAbK8tCoA--kUZNOxB7IznM'\n","    # if downloaded from here, MOVE IT TO THE CORRECT FOLDER (please)\n","    # saved/neuralnets/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2coQiDMpypQE"},"outputs":[],"source":["# choose whether to fine-tune the network from scratch\n","# or to load a pre-trained one (need to specify path)\n","\n","# Models:| efficientnet_b0 | mobilenet_v3_large | efficientnet_v2_s |\n","#        |    resnet50     |     vgg16_bn        ## don't do these (too big) ##\n","\n","ConvNet_Name = 'efficientnet_b0'\n","\n","LoadOrTrain = 'Load'\n","ModelsDir = f'{LocalDir}saved/neuralnets/'"]},{"cell_type":"markdown","metadata":{"id":"k60so4UMgzRr"},"source":["## üÜò Helper functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zx6YPgb6gzRs"},"outputs":[],"source":["# compute True Positives, False Positives, and False Negatives\n","\n","def ConfusionMatrix(ground_truth, predictions, num_classes):\n","    # softmax predictions to have probability distribution (score)\n","    predictions = softmax(predictions)\n","\n","    # pick the class with highest score as actual prediction\n","    pred_score, pred_class = np.max(predictions), np.argmax(predictions)\n","\n","    # initialize True Positives, False Positives, and False Negatives lists\n","    TP, FP, FN = np.zeros(num_classes), np.zeros(num_classes), np.zeros(num_classes)\n","\n","    # Confusion Matrix\n","    if pred_class == ground_truth:\n","        TP[pred_class] += 1\n","    else:\n","        FP[pred_class] += 1\n","        FN[ground_truth] += 1\n","\n","    return TP, FP, FN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mD3q6yN5VWtr"},"outputs":[],"source":["# attach new Configurable Classifier\n","\n","def ConfigurableClassifier(ConvNet, params):#, PreTrained = True):\n","    in_features = params['in']\n","    l1 = params['l1']\n","    l2 = params['l2']\n","    dropout = params['dout']\n","\n","    # load new Classifier\n","    ConvNet.classifier = nn.Sequential(\n","                nn.Linear(in_features, l1),\n","                nn.ReLU(),\n","                nn.Dropout(dropout),\n","                nn.Linear(l1, l2),\n","                nn.ReLU(),\n","                nn.Dropout(dropout),\n","                nn.Linear(l2, 100))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6bDx2eU2iP2y"},"outputs":[],"source":["# load pre-trained model\n","\n","# since torch doesn't provide a clear way to do this, we need to do it manually\n","# it is stupid, we know.\n","def LoadPretrained(ModelName):\n","    #\n","    p = [0,     # Model\n","         0,     # Image Size\n","         0,     # Crop Size\n","         0]     # Batch Size\n","\n","    if ModelName == 'efficientnet_b0':\n","        p = [torchvision.models.efficientnet_b0(weights = 'IMAGENET1K_V1'),256,224,64]\n","    elif ModelName == 'mobilenet_v3_large':\n","        p = [torchvision.models.mobilenet_v3_large(weights = 'IMAGENET1K_V1'),232,224,64]\n","    elif ModelName == 'efficientnet_v2_s':\n","        p = [torchvision.models.efficientnet_v2_s(weights = 'IMAGENET1K_V1'),384,384,24]\n","    elif ModelName == 'resnet50':\n","        p = [torchvision.models.resnet50(weights = 'IMAGENET1K_V1'),256,224,32]\n","    elif ModelName == 'vgg16_bn':\n","        p = [torchvision.models.vgg16_bn(weights = 'IMAGENET1K_V1'),256,224,32]\n","    return p[0], p[1], p[2], p[3]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IjiKsTMdQRrM"},"outputs":[],"source":["# since different models have different architectures, we need to manually change\n","# the classifier\n","# very stupid, we know.\n","\n","def LoadClassifier(ConvNet, ModelName, verbose = False):\n","    if verbose: print(f'before:\\n{ConvNet.classifier}\\n\\n***********************\\n')\n","    i = 1   # index of first linear layer (manually look it up)\n","    if ModelName   == 'mobilenet_v3_large': i = 0\n","    in_f = ConvNet.classifier[i].in_features\n","\n","    if   ModelName == 'efficientnet_b0':    params = {'in': in_f,'l1': 512, 'l2': 256,'dout':0.1}\n","    elif ModelName == 'mobilenet_v3_large': params = {'in': in_f,'l1': 512, 'l2': 256,'dout':0.1}\n","    elif ModelName == 'resnet50':           params = {'in': in_f,'l1': 1024,'l2': 512,'dout':0.3}\n","    elif ModelName == 'vgg16_bn':           params = {'in': in_f,'l1': 2048,'l2': 512,'dout':0.3}\n","    elif ModelName == 'efficientnet_v2_s':  params = {'in': in_f,'l1': 512, 'l2': 256,'dout':0.3}\n","\n","    ConfigurableClassifier(ConvNet, params)\n","    if verbose: print(f'after:\\n{ConvNet.classifier}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"55g8M-DsiQVX"},"outputs":[],"source":["# update network to \"LOCK\" parameters for non-classifier layers\n","\n","def LockParameters(ConvNet):\n","    for key, value in dict(ConvNet.named_children()).items():\n","        if 'classifier' or 'fc' in key:\n","            for param in value.parameters():\n","                param.requires_grad = True\n","        else:\n","            for param in value.parameters():\n","                param.requires_grad = False"]},{"cell_type":"markdown","metadata":{"id":"9a6gkT3HvYSw"},"source":["## ü§ì Definition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mnHO6MGSuUy_"},"outputs":[],"source":["# Load the Entire Model\n","\n","def LoadModel(ModelName, Load = False, verbose = False):\n","        # Load Model\n","        ConvNet, ImageSize, CropSize, BatchSize = LoadPretrained(ModelName)\n","\n","        # Change Classifier\n","        LoadClassifier(ConvNet, ModelName, verbose = verbose)\n","\n","        # Lock Parameters\n","        LockParameters(ConvNet)\n","\n","        if Load:\n","            print(f'Using {ModelsDir}{ModelName}.pth')\n","            ConvNet.load_state_dict(torch.load(f'{ModelsDir}{ModelName}.pth'))\n","\n","        # Send to GPU\n","        ConvNet = ConvNet.to(device)\n","\n","        if verbose: print(f'\\nUsing {ModelName}:\\n\\tImageSize: {CropSize}x{CropSize}\\n\\tBatchSize: {BatchSize}')\n","\n","        return ConvNet, ImageSize, CropSize, BatchSize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X54uBz5CCSZI"},"outputs":[],"source":["# Model Initialization\n","\n","if CNN:\n","    ConvNet, ImageSize, CropSize, BatchSize = LoadModel(ConvNet_Name, Load = False, verbose = True)"]},{"cell_type":"markdown","metadata":{"id":"9Bho7_o1em7B"},"source":["## üóÇÔ∏è Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lwp5cRezCSZI"},"outputs":[],"source":["# Prepare dataset for network training\n","\n","def PrepareData(DataDir, ImageSize, CropSize, BatchSize):\n","    # Images will be resized to this value\n","    ImageSize = ImageSize\n","    # BatchSize for network training\n","    BatchSize = BatchSize\n","    # CropSize for network training\n","    CropSize = CropSize\n","    # Validation batch size multiplier\n","    ValMultiplier = 1 if not BigRam else 4\n","\n","    # Transform to apply to data\n","    transform = transforms.Compose([\n","        transforms.Resize((ImageSize, ImageSize)),\n","        transforms.CenterCrop((CropSize, CropSize)),\n","        transforms.ToTensor()\n","        ,transforms.Normalize(\n","        mean = [0.485, 0.456, 0.406],\n","        std =  [0.229, 0.224, 0.225])\n","    ])\n","\n","    # Datasets initialization\n","    DataToUse = int(PercentageDataToUse * len(data_train))\n","    TrainDataSet = DataSet(DataDir, data_train[:DataToUse], transform)\n","\n","    DataToUse = int(PercentageDataToUse * len(data_val))\n","    ValDataSet = DataSet(DataDir, data_val[:DataToUse], transform)\n","\n","    DataToUse = int(PercentageDataToUse * len(data_test))\n","    TestDataSet = DataSet(DataDir, data_test[:DataToUse], transform)\n","\n","\n","    # Data Loaders for Neural Network batch input\n","    TrainLoader = DataLoader(TrainDataSet, batch_size = BatchSize,                 shuffle = True,  num_workers = 0)\n","    ValLoader   = DataLoader(ValDataSet,   batch_size = BatchSize * ValMultiplier, shuffle = True,  num_workers = 0)\n","    TestLoader  = DataLoader(TestDataSet,  batch_size = 1,                         shuffle = False, num_workers = 0)\n","\n","    return TrainLoader, ValLoader, TestLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FqEMoNCECSZJ"},"outputs":[],"source":["#########################################################################################\n","# Data Preparation for Neural Network\n","#########################################################################################\n","\n","if CNN:\n","    # Images will be resized to this value\n","    ImageSize = ImageSize\n","    # BatchSize for network training\n","    BatchSize = BatchSize\n","    # CropSize for network training\n","    CropSize = CropSize\n","    # Validation batch size multiplier\n","    ValMultiplier = 1 if not BigRam else 4\n","\n","    # Get Data Loaders\n","    TrainLoader, ValLoader, TestLoader = PrepareData(DataDir, ImageSize, CropSize, BatchSize)\n","\n","    # Print Train/Val/Test sizes\n","    NumTraining = len(TrainLoader.dataset)\n","    print(f'Train:\\t{NumTraining} images\\n\\t{len(TrainLoader)} batches')\n","\n","    NumValidation = len(ValLoader.dataset)\n","    print(f'Val:\\t{NumValidation} images\\n\\t{len(ValLoader)} batches')\n","\n","    NumTesting = len(TestLoader.dataset)\n","    print(f'Test:\\t{NumTesting} images\\n\\t{len(TestLoader)} batches')"]},{"cell_type":"markdown","metadata":{"id":"8nqF-w6KvZfV"},"source":["## üèãüèº Training and Validation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z-1B3cEUjoLA"},"outputs":[],"source":["#########################################################################################\n","# Network Training\n","#########################################################################################\n","def TrainAndValidateModel(ConvNet, ModelName, TrainLoader, params, verbose = True):# , NEpochs, patience, criterion, optimizer, scheduler):\n","    ConvNet = ConvNet.to(device)\n","    NEpochs = params['NEpochs']\n","    patience = params['patience']\n","    max_patience = patience\n","    criterion = params['criterion']\n","    optimizer = params['optimizer']\n","    optimizer.param_groups[0]['lr'] = params['learningrate']\n","    scheduler = params['scheduler']\n","\n","    # if loss doesn't get better after this many epochs, stop training\n","    max_patience = 3\n","    patience = patience\n","\n","    # save loss after each epoch\n","    train_losses = []\n","    val_losses = []\n","\n","    # save labels of every image\n","    val_gts = []\n","    val_preds = []\n","\n","    # save the model if model has lowest loss so far\n","    best_loss = np.inf\n","\n","    if verbose: print(f'Training {ModelName} ...\\n')\n","    for epoch in range(NEpochs):\n","        if patience == 0:\n","            if verbose: print('lost patience, killing the network.')\n","            break\n","\n","        running_loss = 0.0\n","        epoch_loss = 0.0\n","        t10 = time.time()\n","\n","        ##################################\n","        # TRAINING                       #\n","        ##################################\n","        ConvNet.train()\n","        if verbose: print(f'EPOCH {epoch+1}------------------------------------------')\n","        if verbose: print('Training:')\n","        tTrain = time.time()\n","        for i, data in enumerate(tqdm(TrainLoader, disable = not verbose)):\n","            # get the inputs\n","            inputs, labels = data\n","            inputs = inputs.to(device)\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # forward + backward + optimize\n","            logits = ConvNet(inputs)\n","            loss = criterion(logits.cuda(), labels.cuda())\n","            loss.backward()\n","\n","            optimizer.step()\n","            scheduler.step()\n","\n","            epoch_loss += loss.item()\n","            running_loss += loss.item()\n","\n","        elapsed = int(time.time() - tTrain)\n","        if verbose: print(f'LOSS: {epoch_loss/i:.5f}')\n","        train_losses.append(epoch_loss/i)\n","\n","\n","        running_loss = 0.0\n","        tValid = time.time()\n","\n","        ##################################\n","        # VALIDATION                     #\n","        ##################################\n","        ConvNet.eval()\n","        if verbose: print(f'Validation:')\n","        for i, data in enumerate(tqdm(ValLoader, disable = not verbose)):\n","            # get the inputs\n","            inputs, labels = data\n","            val_gts.append(labels)\n","\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            # predict labels\n","            with torch.no_grad():\n","                logits = ConvNet(inputs)\n","\n","            # compute validation loss\n","            loss = criterion(logits.cuda(), labels.cuda())\n","\n","            running_loss += loss.item()\n","\n","        elapsed = int(time.time() - tValid)\n","        valLoss = running_loss / len(ValLoader)\n","        if verbose: print(f'LOSS: {valLoss:.5f}', end = '')\n","        val_losses.append(running_loss/len(ValLoader))\n","\n","\n","        # if latest model has best loss, save it\n","        if valLoss < best_loss:\n","            torch.save(ConvNet.state_dict(), f'{ModelsDir}{ModelName}.pth')\n","            best_loss = valLoss\n","            patience = max_patience\n","            if verbose: print(f'\\t*SAVED*')\n","        else:\n","            if verbose: print()\n","            patience -= 1\n","\n","        if verbose: print('\\n')\n","\n","    if verbose: print('Finished Training.')\n","    return train_losses, val_losses, best_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GdUEKwvt8_RH"},"outputs":[],"source":["if CNN:\n","    # Train model\n","    if LoadOrTrain == 'Train':\n","        NEpochs = 10\n","        optimizer = optim.Adam(ConvNet.parameters())\n","        params = {\n","                'NEpochs': 10,                                  # Training Epochs\n","                'patience': 3,                                  # Patience (max number of epochs with no improvement)\n","                'criterion': nn.CrossEntropyLoss(),             # loss criterion\n","                'learningrate': 0.001,                          # learning rate\n","                'optimizer': optimizer,                         # backpropagation optimizer\n","                'scheduler': CosineAnnealingLR(optimizer,       # learning rate scheduler\n","                                  T_max = len(TrainLoader)*(NEpochs//2),\n","                                  eta_min = 1e-5)\n","                }\n","        torch.cuda.empty_cache()\n","        train_losses, val_losses, best_loss = TrainAndValidateModel(ConvNet, ConvNet_Name, TrainLoader, params, verbose = True)\n","        print(f'Done training after {len(val_losses)} epochs.\\n Best val LOSS: {best_loss}')\n","\n","    # Load model\n","    else:\n","        ConvNet.load_state_dict(torch.load(f'{ModelsDir}{ConvNet_Name}.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nGcceNHnjoLA"},"outputs":[],"source":["# plot Training and Validation losses\n","if CNN and LoadOrTrain == 'Train':\n","    plt.figure()\n","    plt.plot(train_losses, label = 'Train')\n","    plt.plot(val_losses, label = 'Val')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.title(f'{ConvNet_Name}')\n","    plt.legend()\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"MTXzm9mgkiSU"},"source":["## üî¨ Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kpM4-3SYCSZK"},"outputs":[],"source":["if CNN:\n","    # Models:| efficientnet_b0 | mobilenet_v3_large |\n","    #        |    resnet50     |     vgg16_bn       | efficientnet_v2_s  |   # don't do these (too big)\n","\n","    ConvNet_Name = 'efficientnet_b0'    # MAKE SURE TO HAVE MODEL IN FOLDER\n","\n","    ConvNet, _, _, _ = LoadModel(ConvNet_Name, Load = True, verbose = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h54DwqwKiGAC"},"outputs":[],"source":["#########################################################################################\n","# Network Testing\n","#########################################################################################\n","\n","def TestModel(ConvNet, ModelName, TestLoader):\n","    ConvNet = ConvNet.to(device)\n","    ConvNet.eval()\n","\n","    # save labels of every image\n","    test_gts = []\n","    test_preds = []\n","\n","    # keep track of True Positives, False Positives, and False Negatives\n","    TP, FP, FN = np.zeros(NumClasses), np.zeros(NumClasses), np.zeros(NumClasses)\n","\n","    print(f'Testing {ModelName} ...\\n')\n","    for i, data in enumerate(tqdm(TestLoader)):\n","        # get the inputs\n","        input, label = data\n","        test_gts.append(label.item())\n","\n","        input = input.to(device)\n","\n","        # predict labels\n","        with torch.no_grad():\n","            outputs = ConvNet(input)\n","            test_preds.append(torch.argmax(outputs))\n","\n","        # calculate ConfusionMatrix to update True Positives, False Positives, and False Negatives\n","        iTP, iFP, iFN = ConfusionMatrix(label.item(), outputs.cpu().numpy(), NumClasses)\n","        TP += iTP\n","        FP += iFP\n","        FN += iFN\n","\n","    return TP, FP, FN, test_gts, test_preds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k9r2RDr29uLO"},"outputs":[],"source":["# Test the model\n","# extract True Positives, False Positives, False Negatives,\n","# test ground truths, test predictions\n","\n","if CNN:\n","    TP, FP, FN, test_gts, test_preds = TestModel(ConvNet, ConvNet_Name, TestLoader)"]},{"cell_type":"markdown","metadata":{"id":"eBARIE1avXYz"},"source":["# üîç Evaluation"]},{"cell_type":"markdown","metadata":{"id":"PYnOt4HRfHGQ"},"source":["## üìê Evaluation Metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"77NIz00Y67hS"},"outputs":[],"source":["# mean Average Accuracy\n","# Compute average accuracy separetly for each class, then average over classes\n","\n","def EvaluatemAA(TP, num_true):\n","    precisions = []\n","    for c in range(1, len(TP)):\n","        precisions.append(EvaluateAccuracy(TP[c], num_true))\n","    return np.mean(precisions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GLASnJva7AHD"},"outputs":[],"source":["# Accuracy\n","# Accuracy = Correct / Total\n","\n","def EvaluateAccuracy(TP, total):\n","    return np.sum(TP)/(total)"]},{"cell_type":"markdown","metadata":{"id":"m6mYZsVgfKYc"},"source":["## üëú Bag of Words"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XOUo2oQcrVst"},"outputs":[],"source":["# compute accuracy of each Classifier\n","\n","if BoW:\n","    accuracies = []\n","    for i, c in enumerate(Classifiers):\n","        nailed = sum(pr == gt for pr, gt in zip(pred_labels_c[i], test_labels))\n","        accuracies.append(nailed / NumTesting)\n","        print(f'Accuracy {str(c)[:3]}:\\t{accuracies[i]:.5f}')"]},{"cell_type":"markdown","metadata":{"id":"gCsaZd6PfPWO"},"source":["## üß† Neural Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aF1bkswSGumr"},"outputs":[],"source":["# compute Accuracy and mean Average Preicision of the Neural Net\n","\n","if CNN:\n","    # count occurrences of each label in dataset\n","    num_true = np.zeros(NumClasses)\n","    for c in Classes:\n","        num_true[c] = np.count_nonzero(np.array(test_gts) == c)\n","\n","    # Accuracy\n","    accuracy = np.sum(TP) / NumTesting\n","\n","    # mean Average Accuracy\n","    mAA = EvaluatemAA(TP, num_true)\n","\n","    # accuracy per class\n","    accuracies = []\n","    for c in Classes:\n","        accuracy_c = EvaluateAccuracy(TP[c], num_true[c])\n","        accuracies.append(accuracy_c)\n","\n","    # plot accuracy\n","    plt.figure(figsize = (12,6))\n","\n","    # accuracy per class\n","    plt.bar(np.arange(NumClasses), accuracies, color = 'tab:blue')\n","\n","    # mean average accuracy\n","    plt.axhline(y = mAA, color = 'black',\n","                linestyle = '-', linewidth = 3\n","                # , label = f'mAA: {mAA:.5f}'\n","                )\n","    plt.annotate(f'mAA {mAA:.3f}', (0-4.2, mAA+0.04), size = 10,\n","                bbox = dict(facecolor='white', edgecolor='black'))\n","\n","\n","    # lowest accuracy class\n","    xmin = np.argmin(TP)\n","    ymin = accuracies[xmin]\n","    plt.bar(xmin, ymin, color = 'tab:olive')\n","    plt.annotate(f'Class {xmin}\\nAccuracy {ymin:.3f}',\n","                 (xmin+1.5, ymin-0.078), size = 10,\n","                 bbox = dict(facecolor='white', edgecolor='tab:olive'))\n","\n","    # highes accuracy class\n","    xmax = np.argmax(TP)\n","    ymax = accuracies[xmax]\n","    plt.bar(xmax, ymax, color = 'tab:orange')\n","    plt.annotate(f'Class {xmax}\\nAccuracy {ymax:.3f}',\n","                 (xmax+1.5, ymax-0.078), size = 10,\n","                 bbox = dict(facecolor='white', edgecolor='tab:orange'))\n","\n","    plt.ylim([0,1.1])\n","    plt.xlabel('Class')\n","    plt.ylabel('Accuracy')\n","    # plt.legend(loc = 'upper left')\n","    plt.title(f'{ConvNet_Name}')\n","    plt.xticks(np.arange(100, step = 10))\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"gPtyZAgNb79a"},"source":["# üìà Hyperparameters Tuning"]},{"cell_type":"markdown","metadata":{"id":"M_i5e3yu1GQ_"},"source":["## üëú Bag of Words"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-XWI8S9A1GRF"},"outputs":[],"source":["if BoWFT:\n","    NWordsList = [x for x in range(400, 5000, 200)]\n","    MBKMeansList = []\n","    inertiaList = []\n","    for n in NWordsList:\n","        ti = time.time()\n","        temp_kmeans = MiniBatchKMeans(n_clusters = n, batch_size = 4* n, n_init = 'auto', random_state = 0).fit(descriptors_flat)\n","        MBKMeansList.append(temp_kmeans)\n","        inertiaList.append(temp_kmeans.inertia_)\n","        print(f'Words: {n}\\t{time.time()-ti}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sJWF-1uzWIKP"},"outputs":[],"source":["plt.figure()\n","plt.scatter(NWordsList,inertiaList)\n","plt.plot(NWordsList, inertiaList)\n","plt.xticks(NWordsList, rotation = 90)\n","plt.title('Inertia vs number of clusters')\n","plt.xlabel('Number of clusters')\n","plt.ylabel('Inertia [a.u.]')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"uuxuJm0b1JQ6"},"source":["## üß† Neural Network\n","- https://towardsdatascience.com/hyperparameter-tuning-of-neural-networks-with-optuna-and-pytorch-22e179efc837"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"46pTDzQ7yOLl"},"outputs":[],"source":["ConvNet_Name = 'efficientnet_b0'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vu_L4pVR8fQD"},"outputs":[],"source":["# define an objective function:\n","#       - load a model with certain parameters,\n","#               train and validate it\n","#       - try to minimize validation loss\n","\n","def objective(trial):\n","        # Load Pre-Trained model\n","        model, _, _, _ = LoadModel(ConvNet_Name, Load = False, verbose = False)\n","\n","        # Modify Classifier\n","        in_features = model.classifier[0].in_features\n","        classifier_params = {\n","                'in':   in_features,\n","                'l1':   trial.suggest_int('l1', low = 512, high = 896, step = 128),\n","                'l2':   trial.suggest_int('l2', low = 128, high = 512, step = 128),\n","                'dout': trial.suggest_float('dout', low = 0.0, high = 1.0, step = 0.2)\n","                }\n","\n","        ConfigurableClassifier(model, classifier_params)\n","\n","        optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'RMSprop', 'SGD'])\n","        lr = trial.suggest_loguniform('lr', 1e-4, 1e-1)\n","        optimizer = getattr(optim, optimizer_name)(model.parameters(), lr = lr)\n","\n","        # Train and Validate Network\n","        train_params = {\n","                        'NEpochs': trial.suggest_int('NEpochs', 5, 10)\n","                        'patience': 2,\n","                        'criterion': nn.CrossEntropyLoss(),\n","                        'learningrate': lr,\n","                        'optimizer': optimizer,\n","                        'scheduler': CosineAnnealingLR(optimizer,\n","                                        T_max = len(TrainLoader)*(5//2),\n","                                        eta_min = 1e-5)\n","                        }\n","        _, _, best_loss = TrainAndValidateModel(model, ConvNet_Name, TrainLoader, train_params, verbose = False)\n","\n","        with open(f'{LocalDir}/saved/study.pkl', 'wb') as f:\n","            pickle.dump(study, f'{LocalDir}saved/study{best_loss}.pkl')\n","        with open(f'{LocalDir}/saved/study.pkl', 'wb') as f:\n","            pickle.dump(study, f'{LocalDir}saved/study{best_loss}.pkl')\n","        # return Validation loss to minimize\n","        return best_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JRs-yP1T7iMn"},"outputs":[],"source":["# Optuna hyper-parameters tuning\n","\n","if CNNFT:\n","    # study initialization\n","    if os.path.isfile(f'{LocalDir}/saved/studies/study.pkl'):\n","        print('Study detected, loading ...')\n","        with open(f'{LocalDir}/saved/studies/study.pkl', 'rb') as f:\n","            study = pickle.load(f)\n","\n","    _, ImageSize, CropSize, BatchSize = LoadModel(ConvNet_Name, Load = False, verbose = False)\n","    TrainLoader, ValLoader, TestLoader = PrepareData(DataDir, ImageSize, CropSize, 8)\n","\n","    study = optuna.create_study(study_name = f'ConvNetSTUDY', direction = \"minimize\", sampler = optuna.samplers.TPESampler())\n","\n","    # study execution üêå.......üêå.................üêå.......................................üêå\n","    study.optimize(objective, n_trials = 30,\n","                    n_jobs = -1, show_progress_bar = True)\n","\n","    # save study\n","    with open(f'{LocalDir}/saved/studies/study{study.best_trial.value}.pkl', 'wb') as f:\n","            pickle.dump(study, f'{LocalDir}/saved/studies/study{study.best_trial.value}.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fTVKvmW5PkEh"},"outputs":[],"source":["# extract best hyperparameters\n","\n","if CNNFT:\n","    best_trial = study.best_trial\n","\n","    for key, value in best_trial.params.items():\n","        print(\"{}: {}\".format(key, value))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ljm_uA7DCSZO"},"outputs":[],"source":["if CNNFT:\n","    fig = optuna.visualization.plot_intermediate_values(study)\n","    fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ggVNpyyCSZO"},"outputs":[],"source":["if CNNFT:\n","    fig = optuna.visualization.plot_optimization_history(study)\n","    fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pe991PkACSZP"},"outputs":[],"source":["if CNNFT:\n","    fig = optuna.visualization.plot_param_importances(study)\n","    fig.show()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["tXBcphwRAgkM","EvAa4VP2BFKT","FnvFofOZmsuz","k9Psiv1-ZwAY","5mxL0qYlCSZB","3BxKTJxAbxYa","eA9JkvMzjoK7","bTosHjMpjoK8","Vn28e_3qFwab","k60so4UMgzRr","9a6gkT3HvYSw","9Bho7_o1em7B","8nqF-w6KvZfV","MTXzm9mgkiSU","eBARIE1avXYz","PYnOt4HRfHGQ","m6mYZsVgfKYc","gCsaZd6PfPWO","M_i5e3yu1GQ_","uuxuJm0b1JQ6"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}
